{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6753336",
   "metadata": {},
   "source": [
    "# cjm-text-plugin-system\n",
    "\n",
    "> Defines standardized interfaces and data structures for text processing plugins, enabling modular NLP operations like sentence splitting, tokenization, and chunking within the cjm-plugin-system ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42817100",
   "metadata": {},
   "source": [
    "## Install\n",
    "\n",
    "```bash\n",
    "pip install cjm_text_plugin_system\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f942c58c",
   "metadata": {},
   "source": [
    "## Project Structure\n",
    "\n",
    "```\n",
    "nbs/\n",
    "├── core.ipynb             # DTOs for text processing with character-level span tracking\n",
    "├── plugin_interface.ipynb # Domain-specific plugin interface for text processing operations\n",
    "└── storage.ipynb          # Standardized SQLite storage for text processing results with content hashing\n",
    "```\n",
    "\n",
    "Total: 3 notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c619347",
   "metadata": {},
   "source": [
    "## Module Dependencies\n",
    "\n",
    "```mermaid\n",
    "graph LR\n",
    "    core[core<br/>Core Data Structures]\n",
    "    plugin_interface[plugin_interface<br/>Text Processing Plugin Interface]\n",
    "    storage[storage<br/>Text Processing Storage]\n",
    "\n",
    "    plugin_interface --> core\n",
    "```\n",
    "\n",
    "*1 cross-module dependencies detected*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09cd266",
   "metadata": {},
   "source": [
    "## CLI Reference\n",
    "\n",
    "No CLI commands found in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac74ef28",
   "metadata": {},
   "source": [
    "## Module Overview\n",
    "\n",
    "Detailed documentation for each module in the project:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ad6ce2",
   "metadata": {},
   "source": [
    "### Core Data Structures (`core.ipynb`)\n",
    "> DTOs for text processing with character-level span tracking\n",
    "\n",
    "#### Import\n",
    "\n",
    "```python\n",
    "from cjm_text_plugin_system.core import (\n",
    "    TextSpan,\n",
    "    TextProcessResult\n",
    ")\n",
    "```\n",
    "#### Classes\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class TextSpan:\n",
    "    \"Represents a segment of text with its original character coordinates.\"\n",
    "    \n",
    "    text: str  # The text content of this span\n",
    "    start_char: int  # 0-indexed start position in original string\n",
    "    end_char: int  # 0-indexed end position (exclusive)\n",
    "    label: str = 'sentence'  # Span type: 'sentence', 'token', 'paragraph', etc.\n",
    "    metadata: Dict[str, Any] = field(...)  # Additional span metadata\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:  # Dictionary representation\n",
    "        \"Convert span to dictionary for serialization.\"\n",
    "```\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class TextProcessResult:\n",
    "    \"Container for text processing results.\"\n",
    "    \n",
    "    spans: List[TextSpan]  # List of text spans from processing\n",
    "    metadata: Dict[str, Any] = field(...)  # Processing metadata\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b969e319",
   "metadata": {},
   "source": [
    "### Text Processing Plugin Interface (`plugin_interface.ipynb`)\n",
    "> Domain-specific plugin interface for text processing operations\n",
    "\n",
    "#### Import\n",
    "\n",
    "```python\n",
    "from cjm_text_plugin_system.plugin_interface import (\n",
    "    TextProcessingPlugin\n",
    ")\n",
    "```\n",
    "#### Classes\n",
    "\n",
    "```python\n",
    "class TextProcessingPlugin(PluginInterface):\n",
    "    \"\"\"\n",
    "    Abstract base class for plugins that perform NLP operations.\n",
    "    \n",
    "    Extends PluginInterface with text processing requirements:\n",
    "    - `execute`: Dispatch method for different text operations\n",
    "    - `split_sentences`: Split text into sentence spans with character positions\n",
    "    \"\"\"\n",
    "    \n",
    "    def execute(\n",
    "            self,\n",
    "            action: str = \"split_sentences\",  # Operation to perform: 'split_sentences', 'tokenize', etc.\n",
    "            **kwargs\n",
    "        ) -> Dict[str, Any]:  # JSON-serializable result\n",
    "        \"Execute a text processing operation.\"\n",
    "    \n",
    "    def split_sentences(\n",
    "            self,\n",
    "            text: str,  # Input text to split\n",
    "            **kwargs\n",
    "        ) -> TextProcessResult:  # Result with TextSpan objects containing character indices\n",
    "        \"Split text into sentence spans with accurate character positions.\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f212fe50",
   "metadata": {},
   "source": [
    "### Text Processing Storage (`storage.ipynb`)\n",
    "> Standardized SQLite storage for text processing results with content hashing\n",
    "\n",
    "#### Import\n",
    "\n",
    "```python\n",
    "from cjm_text_plugin_system.storage import (\n",
    "    TextProcessRow,\n",
    "    TextProcessStorage\n",
    ")\n",
    "```\n",
    "#### Classes\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class TextProcessRow:\n",
    "    \"A single row from the text_jobs table.\"\n",
    "    \n",
    "    job_id: str  # Unique job identifier\n",
    "    input_text: str  # Original input text\n",
    "    input_hash: str  # Hash of input text in \"algo:hexdigest\" format\n",
    "    spans: Optional[List[Dict[str, Any]]]  # Processed text spans\n",
    "    metadata: Optional[Dict[str, Any]]  # Processing metadata\n",
    "    created_at: Optional[float]  # Unix timestamp\n",
    "```\n",
    "\n",
    "```python\n",
    "class TextProcessStorage:\n",
    "    def __init__(\n",
    "        self,\n",
    "        db_path: str  # Absolute path to the SQLite database file\n",
    "    )\n",
    "    \"Standardized SQLite storage for text processing results.\"\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            db_path: str  # Absolute path to the SQLite database file\n",
    "        )\n",
    "        \"Initialize storage and create table if needed.\"\n",
    "    \n",
    "    def save(\n",
    "            self,\n",
    "            job_id: str,       # Unique job identifier\n",
    "            input_text: str,   # Original input text\n",
    "            input_hash: str,   # Hash of input text in \"algo:hexdigest\" format\n",
    "            spans: Optional[List[Dict[str, Any]]] = None,  # Processed text spans\n",
    "            metadata: Optional[Dict[str, Any]] = None       # Processing metadata\n",
    "        ) -> None\n",
    "        \"Save a text processing result to the database.\"\n",
    "    \n",
    "    def get_by_job_id(\n",
    "            self,\n",
    "            job_id: str  # Job identifier to look up\n",
    "        ) -> Optional[TextProcessRow]:  # Row or None if not found\n",
    "        \"Retrieve a text processing result by job ID.\"\n",
    "    \n",
    "    def list_jobs(\n",
    "            self,\n",
    "            limit: int = 100  # Maximum number of rows to return\n",
    "        ) -> List[TextProcessRow]:  # List of text processing rows\n",
    "        \"List text processing jobs ordered by creation time (newest first).\"\n",
    "    \n",
    "    def verify_input(\n",
    "            self,\n",
    "            job_id: str  # Job identifier to verify\n",
    "        ) -> Optional[bool]:  # True if input matches, False if changed, None if not found\n",
    "        \"Verify the stored input text still matches its hash.\"\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
