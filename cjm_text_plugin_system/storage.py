"""Standardized SQLite storage for text processing results with content hashing"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/storage.ipynb.

# %% auto #0
__all__ = ['TextProcessRow', 'TextProcessStorage']

# %% ../nbs/storage.ipynb #cell-imports
import json
import sqlite3
import time
from dataclasses import dataclass
from typing import Any, Dict, List, Optional

from cjm_plugin_system.utils.hashing import hash_bytes

# %% ../nbs/storage.ipynb #cell-row-dataclass
@dataclass
class TextProcessRow:
    """A single row from the text_jobs table."""
    job_id: str          # Unique job identifier
    input_text: str      # Original input text
    input_hash: str      # Hash of input text in "algo:hexdigest" format
    spans: Optional[List[Dict[str, Any]]] = None  # Processed text spans
    metadata: Optional[Dict[str, Any]] = None      # Processing metadata
    created_at: Optional[float] = None              # Unix timestamp

# %% ../nbs/storage.ipynb #cell-storage-class
class TextProcessStorage:
    """Standardized SQLite storage for text processing results."""

    SCHEMA = """
        CREATE TABLE IF NOT EXISTS text_jobs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            job_id TEXT UNIQUE NOT NULL,
            input_text TEXT NOT NULL,
            input_hash TEXT NOT NULL,
            spans JSON,
            metadata JSON,
            created_at REAL NOT NULL
        )
    """

    INDEX = "CREATE INDEX IF NOT EXISTS idx_text_jobs_job_id ON text_jobs(job_id);"

    def __init__(
        self,
        db_path: str  # Absolute path to the SQLite database file
    ):
        """Initialize storage and create table if needed."""
        self.db_path = db_path
        with sqlite3.connect(self.db_path) as con:
            con.execute(self.SCHEMA)
            con.execute(self.INDEX)

    def save(
        self,
        job_id: str,       # Unique job identifier
        input_text: str,   # Original input text
        input_hash: str,   # Hash of input text in "algo:hexdigest" format
        spans: Optional[List[Dict[str, Any]]] = None,  # Processed text spans
        metadata: Optional[Dict[str, Any]] = None       # Processing metadata
    ) -> None:
        """Save a text processing result to the database."""
        with sqlite3.connect(self.db_path) as con:
            con.execute(
                """INSERT INTO text_jobs
                   (job_id, input_text, input_hash, spans, metadata, created_at)
                   VALUES (?, ?, ?, ?, ?, ?)""",
                (
                    job_id,
                    input_text,
                    input_hash,
                    json.dumps(spans) if spans else None,
                    json.dumps(metadata) if metadata else None,
                    time.time()
                )
            )

    def get_by_job_id(
        self,
        job_id: str  # Job identifier to look up
    ) -> Optional[TextProcessRow]:  # Row or None if not found
        """Retrieve a text processing result by job ID."""
        with sqlite3.connect(self.db_path) as con:
            cur = con.execute(
                """SELECT job_id, input_text, input_hash, spans, metadata, created_at
                   FROM text_jobs WHERE job_id = ?""",
                (job_id,)
            )
            row = cur.fetchone()
            if not row:
                return None
            return TextProcessRow(
                job_id=row[0],
                input_text=row[1],
                input_hash=row[2],
                spans=json.loads(row[3]) if row[3] else None,
                metadata=json.loads(row[4]) if row[4] else None,
                created_at=row[5]
            )

    def list_jobs(
        self,
        limit: int = 100  # Maximum number of rows to return
    ) -> List[TextProcessRow]:  # List of text processing rows
        """List text processing jobs ordered by creation time (newest first)."""
        results = []
        with sqlite3.connect(self.db_path) as con:
            cur = con.execute(
                """SELECT job_id, input_text, input_hash, spans, metadata, created_at
                   FROM text_jobs ORDER BY created_at DESC LIMIT ?""",
                (limit,)
            )
            for row in cur:
                results.append(TextProcessRow(
                    job_id=row[0],
                    input_text=row[1],
                    input_hash=row[2],
                    spans=json.loads(row[3]) if row[3] else None,
                    metadata=json.loads(row[4]) if row[4] else None,
                    created_at=row[5]
                ))
        return results

    def verify_input(
        self,
        job_id: str  # Job identifier to verify
    ) -> Optional[bool]:  # True if input matches, False if changed, None if not found
        """Verify the stored input text still matches its hash."""
        row = self.get_by_job_id(job_id)
        if not row:
            return None
        current_hash = hash_bytes(row.input_text.encode())
        return current_hash == row.input_hash
